{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bbc730",
   "metadata": {},
   "source": [
    "# SigTKAN avec Boucle Manuelle - Pr√©diction de S√©ries Temporelles\n",
    "\n",
    "Ce notebook impl√©mente une version de SigTKAN avec une boucle manuelle (sans h√©riter de la classe RNN de Keras) pour tester l'am√©lioration des performances gr√¢ce √† l'int√©gration des signatures dans le TKAN.\n",
    "\n",
    "## Objectifs:\n",
    "1. Impl√©menter SigTKAN avec une boucle manuelle\n",
    "2. Comparer les performances avec TKAN standard et autres mod√®les\n",
    "3. Tester sur la pr√©diction de volume/volatilit√© de cryptomonnaies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b04fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ Nettoyage et setup initial\n",
    "import os, sys, shutil\n",
    "\n",
    "# 1. Revenir √† la racine\n",
    "os.chdir(\"/content\")\n",
    "print(\"üìç R√©pertoire actuel :\", os.getcwd())\n",
    "\n",
    "# 2. Supprimer toute copie existante de SigKAN\n",
    "if os.path.exists(\"sigtkan\"):\n",
    "    shutil.rmtree(\"sigtkan\")\n",
    "    print(\"üßπ Dossier sigtkan supprim√©\")\n",
    "\n",
    "# 3. Cloner le d√©p√¥t GitHub\n",
    "!git clone https://github.com/julienmoury/sigtkan.git\n",
    "%cd TKAN\n",
    "\n",
    "# 4. Ajouter le projet au PYTHONPATH\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# 5. Installer les d√©pendances\n",
    "if os.path.exists(\"requirements.txt\"):\n",
    "    %pip install -r requirements.txt\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de requirements.txt trouv√©\")\n",
    "\n",
    "# 6. Afficher o√π on est et ce qu‚Äôon a\n",
    "print(\"üìÇ R√©pertoire courant :\", os.getcwd())\n",
    "print(\"üìÅ Contenu :\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Installer les packages n√©cessaires si pas d√©j√† fait\n",
    "try:\n",
    "    import keras_efficient_kan\n",
    "    import keras_sig\n",
    "except ImportError:\n",
    "    print(\"Installation des d√©pendances manquantes...\")\n",
    "    os.system(\"pip install keras-efficient-kan keras-sig\")\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configuration pour la reproductibilit√©\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Setup termin√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60131f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des modules locaux\n",
    "from keras_efficient_kan import KANLinear\n",
    "from keras_sig import SigLayer\n",
    "from sigtkan import SigTKANCell  # Pour comparaison avec la version RNN\n",
    "\n",
    "# Import des autres mod√®les pour comparaison\n",
    "try:\n",
    "    from tkan import TKAN\n",
    "    from sigkan import SigKAN\n",
    "    print(\"Modules TKAN et SigKAN import√©s avec succ√®s\")\n",
    "except ImportError as e:\n",
    "    print(f\"Erreur d'import: {e}\")\n",
    "    print(\"Certains modules de comparaison ne sont pas disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fff66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    \"\"\"Scaler MinMax personnalis√© pour g√©rer diff√©rentes dimensions de donn√©es.\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_axis=None, minmax_range=(0, 1)):\n",
    "        self.feature_axis = feature_axis\n",
    "        self.min_ = None\n",
    "        self.max_ = None\n",
    "        self.scale_ = None\n",
    "        self.minmax_range = minmax_range\n",
    "\n",
    "    def fit(self, X):\n",
    "        if X.ndim == 3 and self.feature_axis is not None:\n",
    "            axis = tuple(i for i in range(X.ndim) if i != self.feature_axis)\n",
    "            self.min_ = np.min(X, axis=axis)\n",
    "            self.max_ = np.max(X, axis=axis)\n",
    "        elif X.ndim == 2:\n",
    "            self.min_ = np.min(X, axis=0)\n",
    "            self.max_ = np.max(X, axis=0)\n",
    "        elif X.ndim == 1:\n",
    "            self.min_ = np.min(X)\n",
    "            self.max_ = np.max(X)\n",
    "        else:\n",
    "            raise ValueError(\"Data must be 1D, 2D, or 3D.\")\n",
    "\n",
    "        self.scale_ = self.max_ - self.min_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_scaled = (X - self.min_) / (self.scale_ + 1e-8)  # √âviter division par z√©ro\n",
    "        X_scaled = X_scaled * (self.minmax_range[1] - self.minmax_range[0]) + self.minmax_range[0]\n",
    "        return X_scaled\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def inverse_transform(self, X_scaled):\n",
    "        X = (X_scaled - self.minmax_range[0]) / (self.minmax_range[1] - self.minmax_range[0])\n",
    "        X = X * self.scale_ + self.min_\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132fc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package=\"sigtkan_manual\", name=\"SigTKANManual\")\n",
    "class SigTKANManual(Layer):\n",
    "    \"\"\"\n",
    "    Impl√©mentation manuelle de SigTKAN sans h√©riter de RNN.\n",
    "    Cette version impl√©mente explicitement la boucle temporelle.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        units,\n",
    "        sig_level=2,\n",
    "        sub_kan_configs=None,\n",
    "        sub_kan_output_dim=None,\n",
    "        sub_kan_input_dim=None,\n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.sig_level = sig_level\n",
    "        self.sub_kan_configs = sub_kan_configs or [None]\n",
    "        self.sub_kan_output_dim = sub_kan_output_dim\n",
    "        self.sub_kan_input_dim = sub_kan_input_dim\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.recurrent_activation = tf.keras.activations.get(recurrent_activation)\n",
    "        self.return_sequences = return_sequences\n",
    "        self.return_state = return_state\n",
    "        \n",
    "        # Param√®tres internes\n",
    "        self.cell = None\n",
    "        self.built_cell = False\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        batch_size, sequence_length, input_dim = input_shape\n",
    "        \n",
    "        # D√©finir les dimensions par d√©faut si non sp√©cifi√©es\n",
    "        if self.sub_kan_input_dim is None:\n",
    "            self.sub_kan_input_dim = input_dim\n",
    "        if self.sub_kan_output_dim is None:\n",
    "            self.sub_kan_output_dim = input_dim\n",
    "            \n",
    "        # Cr√©er une cellule SigTKAN pour les op√©rations internes\n",
    "        self.cell = SigTKANCell(\n",
    "            units=self.units,\n",
    "            sig_level=self.sig_level,\n",
    "            sub_kan_configs=self.sub_kan_configs,\n",
    "            sub_kan_output_dim=self.sub_kan_output_dim,\n",
    "            sub_kan_input_dim=self.sub_kan_input_dim,\n",
    "            activation=self.activation,\n",
    "            recurrent_activation=self.recurrent_activation\n",
    "        )\n",
    "        \n",
    "        # Construire la cellule avec la forme d'entr√©e appropri√©e\n",
    "        self.cell.build((batch_size, input_dim))\n",
    "        self.built_cell = True\n",
    "        \n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, initial_state=None, training=None):\n",
    "        \"\"\"\n",
    "        Boucle manuelle sur la s√©quence temporelle.\n",
    "        \n",
    "        Args:\n",
    "            inputs: Tensor de forme (batch_size, sequence_length, input_dim)\n",
    "            initial_state: √âtat initial (optionnel)\n",
    "            training: Mode d'entra√Ænement\n",
    "        \n",
    "        Returns:\n",
    "            outputs: Sorties selon return_sequences\n",
    "            states: √âtats finaux si return_state=True\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        sequence_length = tf.shape(inputs)[1]\n",
    "        \n",
    "        # Initialiser les √©tats si non fournis\n",
    "        if initial_state is None:\n",
    "            states = self.cell.get_initial_state(\n",
    "                inputs=inputs, \n",
    "                batch_size=batch_size, \n",
    "                dtype=inputs.dtype\n",
    "            )\n",
    "        else:\n",
    "            states = initial_state\n",
    "        \n",
    "        # Pr√©parer les conteneurs pour les sorties\n",
    "        if self.return_sequences:\n",
    "            outputs = tf.TensorArray(\n",
    "                dtype=inputs.dtype,\n",
    "                size=sequence_length,\n",
    "                dynamic_size=False\n",
    "            )\n",
    "        \n",
    "        # Boucle manuelle sur la s√©quence\n",
    "        for t in range(sequence_length):\n",
    "            # Extraire l'entr√©e au temps t\n",
    "            input_t = inputs[:, t, :]\n",
    "            \n",
    "            # Appliquer la cellule SigTKAN\n",
    "            output_t, states = self.cell(input_t, states, training=training)\n",
    "            \n",
    "            # Stocker les sorties si n√©cessaire\n",
    "            if self.return_sequences:\n",
    "                outputs = outputs.write(t, output_t)\n",
    "        \n",
    "        # Pr√©parer les r√©sultats finaux\n",
    "        if self.return_sequences:\n",
    "            # Empiler toutes les sorties temporelles\n",
    "            outputs = outputs.stack()\n",
    "            outputs = tf.transpose(outputs, [1, 0, 2])  # (batch, time, features)\n",
    "            final_output = outputs\n",
    "        else:\n",
    "            # Retourner seulement la derni√®re sortie\n",
    "            final_output = output_t\n",
    "        \n",
    "        if self.return_state:\n",
    "            return final_output, states\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"units\": self.units,\n",
    "            \"sig_level\": self.sig_level,\n",
    "            \"sub_kan_configs\": self.sub_kan_configs,\n",
    "            \"sub_kan_output_dim\": self.sub_kan_output_dim,\n",
    "            \"sub_kan_input_dim\": self.sub_kan_input_dim,\n",
    "            \"activation\": tf.keras.activations.serialize(self.activation),\n",
    "            \"recurrent_activation\": tf.keras.activations.serialize(self.recurrent_activation),\n",
    "            \"return_sequences\": self.return_sequences,\n",
    "            \"return_state\": self.return_state,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e569982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement et pr√©paration des donn√©es\n",
    "df = pd.read_parquet('data.parquet')\n",
    "df = df[(df.index >= pd.Timestamp('2020-01-01')) & (df.index < pd.Timestamp('2023-01-01'))]\n",
    "\n",
    "# S√©lection des actifs crypto\n",
    "assets = ['BTC', 'ETH', 'ADA', 'XMR', 'EOS', 'MATIC', 'TRX', 'FTM', 'BNB', 'XLM', \n",
    "          'ENJ', 'CHZ', 'BUSD', 'ATOM', 'LINK', 'ETC', 'XRP', 'BCH', 'LTC']\n",
    "\n",
    "# Filtrage pour les volumes de quote asset\n",
    "df = df[[c for c in df.columns if 'quote asset volume' in c and any(asset in c for asset in assets)]]\n",
    "df.columns = [c.replace(' quote asset volume', '') for c in df.columns]\n",
    "\n",
    "# Cr√©ation des features temporelles connues\n",
    "known_input_df = pd.DataFrame(\n",
    "    index=df.index, \n",
    "    data=np.array([\n",
    "        df.reset_index()['group'].apply(lambda x: x.hour).values, \n",
    "        df.reset_index()['group'].apply(lambda x: x.dayofweek).values\n",
    "    ]).T, \n",
    "    columns=['hour', 'dayofweek']\n",
    ")\n",
    "\n",
    "print(f\"Donn√©es charg√©es: {df.shape}\")\n",
    "print(f\"P√©riode: {df.index.min()} √† {df.index.max()}\")\n",
    "print(f\"Colonnes: {list(df.columns[:5])}...\" if len(df.columns) > 5 else f\"Colonnes: {list(df.columns)}\")\n",
    "\n",
    "display(df.head())\n",
    "display(known_input_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2afddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(df, sequence_length, n_ahead):\n",
    "    \"\"\"\n",
    "    G√©n√®re les s√©quences pour l'entra√Ænement des mod√®les.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame avec les donn√©es temporelles\n",
    "        sequence_length: Longueur des s√©quences d'entr√©e\n",
    "        n_ahead: Nombre de pas de temps √† pr√©dire\n",
    "    \n",
    "    Returns:\n",
    "        Donn√©es d'entra√Ænement et de test pr√©par√©es\n",
    "    \"\"\"\n",
    "    # Normalisation avec m√©diane mobile\n",
    "    scaler_df = df.copy().shift(n_ahead).rolling(24 * 14).median()\n",
    "    tmp_df = df.copy() / scaler_df\n",
    "    tmp_df = tmp_df.iloc[24 * 14 + n_ahead:].fillna(0.)\n",
    "    scaler_df = scaler_df.iloc[24 * 14 + n_ahead:].fillna(0.)\n",
    "    \n",
    "    def prepare_sequences(df, scaler_df, n_history, n_future):\n",
    "        X, y, y_scaler = [], [], []\n",
    "        \n",
    "        for i in range(n_history, len(df) - n_future + 1):\n",
    "            # S√©quence d'entr√©e\n",
    "            X.append(df.iloc[i - n_history:i].values)\n",
    "            # Valeurs √† pr√©dire (premi√®re colonne seulement)\n",
    "            y.append(df.iloc[i:i + n_future, 0:1].values)\n",
    "            # Facteur de d√©normalisation\n",
    "            y_scaler.append(scaler_df.iloc[i:i + n_future, 0:1].values)\n",
    "        \n",
    "        return np.array(X), np.array(y), np.array(y_scaler)\n",
    "    \n",
    "    # Pr√©paration des s√©quences\n",
    "    X, y, y_scaler = prepare_sequences(tmp_df, scaler_df, sequence_length, n_ahead)\n",
    "    \n",
    "    # Division train/test\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(len(X) * train_ratio)\n",
    "    \n",
    "    X_train_raw, X_test_raw = X[:train_size], X[train_size:]\n",
    "    y_train_raw, y_test_raw = y[:train_size], y[train_size:]\n",
    "    y_scaler_train, y_scaler_test = y_scaler[:train_size], y_scaler[train_size:]\n",
    "    \n",
    "    # Normalisation des features\n",
    "    X_scaler = MinMaxScaler(feature_axis=2)\n",
    "    X_train = X_scaler.fit_transform(X_train_raw)\n",
    "    X_test = X_scaler.transform(X_test_raw)\n",
    "    \n",
    "    # Normalisation des targets\n",
    "    y_scaler_norm = MinMaxScaler(feature_axis=2)\n",
    "    y_train = y_scaler_norm.fit_transform(y_train_raw).reshape(y_train_raw.shape[0], -1)\n",
    "    y_test = y_scaler_norm.transform(y_test_raw).reshape(y_test_raw.shape[0], -1)\n",
    "    \n",
    "    return {\n",
    "        'X_scaler': X_scaler,\n",
    "        'X_train': X_train, 'X_test': X_test,\n",
    "        'X_train_raw': X_train_raw, 'X_test_raw': X_test_raw,\n",
    "        'y_scaler': y_scaler_norm,\n",
    "        'y_train': y_train, 'y_test': y_test,\n",
    "        'y_train_raw': y_train_raw, 'y_test_raw': y_test_raw,\n",
    "        'y_scaler_train': y_scaler_train, 'y_scaler_test': y_scaler_test\n",
    "    }\n",
    "\n",
    "# Param√®tres\n",
    "SEQUENCE_LENGTH = 24  # 24 heures d'historique\n",
    "N_AHEAD = 6          # Pr√©dire 6 heures √† l'avance\n",
    "\n",
    "# G√©n√©ration des donn√©es\n",
    "print(\"G√©n√©ration des s√©quences...\")\n",
    "data = generate_sequences(df, SEQUENCE_LENGTH, N_AHEAD)\n",
    "\n",
    "print(f\"Forme X_train: {data['X_train'].shape}\")\n",
    "print(f\"Forme y_train: {data['y_train'].shape}\")\n",
    "print(f\"Forme X_test: {data['X_test'].shape}\")\n",
    "print(f\"Forme y_test: {data['y_test'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87616a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sigtkan_manual_model(input_shape, units=64, sig_level=2):\n",
    "    \"\"\"\n",
    "    Cr√©e un mod√®le avec SigTKAN manuel.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input_sequence')\n",
    "    \n",
    "    # Couche SigTKAN manuelle\n",
    "    sigtkan_out = SigTKANManual(\n",
    "        units=units,\n",
    "        sig_level=sig_level,\n",
    "        return_sequences=False,\n",
    "        name='sigtkan_manual'\n",
    "    )(inputs)\n",
    "    \n",
    "    # Couches de sortie\n",
    "    dense1 = Dense(units//2, activation='relu', name='dense1')(sigtkan_out)\n",
    "    outputs = Dense(N_AHEAD, activation='linear', name='output')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='SigTKAN_Manual')\n",
    "    return model\n",
    "\n",
    "def create_baseline_lstm_model(input_shape, units=64):\n",
    "    \"\"\"\n",
    "    Cr√©e un mod√®le LSTM de r√©f√©rence.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input_sequence')\n",
    "    \n",
    "    lstm_out = tf.keras.layers.LSTM(\n",
    "        units=units,\n",
    "        return_sequences=False,\n",
    "        name='lstm'\n",
    "    )(inputs)\n",
    "    \n",
    "    dense1 = Dense(units//2, activation='relu', name='dense1')(lstm_out)\n",
    "    outputs = Dense(N_AHEAD, activation='linear', name='output')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='LSTM_Baseline')\n",
    "    return model\n",
    "\n",
    "def create_baseline_gru_model(input_shape, units=64):\n",
    "    \"\"\"\n",
    "    Cr√©e un mod√®le GRU de r√©f√©rence.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input_sequence')\n",
    "    \n",
    "    gru_out = tf.keras.layers.GRU(\n",
    "        units=units,\n",
    "        return_sequences=False,\n",
    "        name='gru'\n",
    "    )(inputs)\n",
    "    \n",
    "    dense1 = Dense(units//2, activation='relu', name='dense1')(gru_out)\n",
    "    outputs = Dense(N_AHEAD, activation='linear', name='output')(dense1)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='GRU_Baseline')\n",
    "    return model\n",
    "\n",
    "# Forme d'entr√©e\n",
    "input_shape = (SEQUENCE_LENGTH, data['X_train'].shape[2])\n",
    "print(f\"Forme d'entr√©e: {input_shape}\")\n",
    "\n",
    "# Cr√©ation des mod√®les\n",
    "print(\"Cr√©ation des mod√®les...\")\n",
    "sigtkan_model = create_sigtkan_manual_model(input_shape)\n",
    "lstm_model = create_baseline_lstm_model(input_shape)\n",
    "gru_model = create_baseline_gru_model(input_shape)\n",
    "\n",
    "print(\"Mod√®les cr√©√©s avec succ√®s!\")\n",
    "print(f\"SigTKAN param√®tres: {sigtkan_model.count_params():,}\")\n",
    "print(f\"LSTM param√®tres: {lstm_model.count_params():,}\")\n",
    "print(f\"GRU param√®tres: {gru_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de l'entra√Ænement\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "# Fonction d'entra√Ænement\n",
    "def train_model(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Entra√Ænement du mod√®le: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Compilation\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Temps d'entra√Ænement: {training_time:.2f} secondes\")\n",
    "    \n",
    "    return history, training_time\n",
    "\n",
    "# Dictionnaire pour stocker les r√©sultats\n",
    "results = {}\n",
    "models = {\n",
    "    'SigTKAN_Manual': sigtkan_model,\n",
    "    'LSTM_Baseline': lstm_model,\n",
    "    'GRU_Baseline': gru_model\n",
    "}\n",
    "\n",
    "print(\"D√©but de l'entra√Ænement des mod√®les...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42748c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement de tous les mod√®les\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        history, training_time = train_model(\n",
    "            model, model_name, \n",
    "            data['X_train'], data['y_train'],\n",
    "            data['X_test'], data['y_test']\n",
    "        )\n",
    "        \n",
    "        # Pr√©dictions\n",
    "        y_pred_train = model.predict(data['X_train'], verbose=0)\n",
    "        y_pred_test = model.predict(data['X_test'], verbose=0)\n",
    "        \n",
    "        # M√©triques\n",
    "        train_mse = mean_squared_error(data['y_train'], y_pred_train)\n",
    "        test_mse = mean_squared_error(data['y_test'], y_pred_test)\n",
    "        train_mae = mean_absolute_error(data['y_train'], y_pred_train)\n",
    "        test_mae = mean_absolute_error(data['y_test'], y_pred_test)\n",
    "        train_r2 = r2_score(data['y_train'], y_pred_train)\n",
    "        test_r2 = r2_score(data['y_test'], y_pred_test)\n",
    "        \n",
    "        # Stockage des r√©sultats\n",
    "        results[model_name] = {\n",
    "            'model': model,\n",
    "            'history': history,\n",
    "            'training_time': training_time,\n",
    "            'y_pred_train': y_pred_train,\n",
    "            'y_pred_test': y_pred_test,\n",
    "            'metrics': {\n",
    "                'train_mse': train_mse,\n",
    "                'test_mse': test_mse,\n",
    "                'train_mae': train_mae,\n",
    "                'test_mae': test_mae,\n",
    "                'train_r2': train_r2,\n",
    "                'test_r2': test_r2\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{model_name} - R√©sultats:\")\n",
    "        print(f\"  Train MSE: {train_mse:.6f}\")\n",
    "        print(f\"  Test MSE: {test_mse:.6f}\")\n",
    "        print(f\"  Train R¬≤: {train_r2:.4f}\")\n",
    "        print(f\"  Test R¬≤: {test_r2:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'entra√Ænement de {model_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\nEntra√Ænement termin√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825cf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des r√©sultats\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARAISON DES PERFORMANCES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tableau de comparaison\n",
    "comparison_data = []\n",
    "for model_name, result in results.items():\n",
    "    metrics = result['metrics']\n",
    "    comparison_data.append({\n",
    "        'Mod√®le': model_name,\n",
    "        'Train MSE': f\"{metrics['train_mse']:.6f}\",\n",
    "        'Test MSE': f\"{metrics['test_mse']:.6f}\",\n",
    "        'Train R¬≤': f\"{metrics['train_r2']:.4f}\",\n",
    "        'Test R¬≤': f\"{metrics['test_r2']:.4f}\",\n",
    "        'Temps (s)': f\"{result['training_time']:.1f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "display(comparison_df)\n",
    "\n",
    "# Trouver le meilleur mod√®le\n",
    "best_model_name = min(results.keys(), key=lambda x: results[x]['metrics']['test_mse'])\n",
    "print(f\"\\nüèÜ Meilleur mod√®le (Test MSE): {best_model_name}\")\n",
    "\n",
    "# Graphiques de comparaison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].set_title('Courbes de Loss')\n",
    "for model_name, result in results.items():\n",
    "    if 'history' in result:\n",
    "        history = result['history']\n",
    "        axes[0, 0].plot(history.history['loss'], label=f'{model_name} (train)')\n",
    "        axes[0, 0].plot(history.history['val_loss'], '--', label=f'{model_name} (val)')\n",
    "axes[0, 0].set_xlabel('√âpoque')\n",
    "axes[0, 0].set_ylabel('Loss (MSE)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_yscale('log')\n",
    "\n",
    "# Test MSE comparison\n",
    "model_names = list(results.keys())\n",
    "test_mse_values = [results[name]['metrics']['test_mse'] for name in model_names]\n",
    "axes[0, 1].bar(model_names, test_mse_values)\n",
    "axes[0, 1].set_title('Test MSE par mod√®le')\n",
    "axes[0, 1].set_ylabel('MSE')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# R¬≤ comparison\n",
    "test_r2_values = [results[name]['metrics']['test_r2'] for name in model_names]\n",
    "axes[1, 0].bar(model_names, test_r2_values)\n",
    "axes[1, 0].set_title('Test R¬≤ par mod√®le')\n",
    "axes[1, 0].set_ylabel('R¬≤')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Training time comparison\n",
    "training_times = [result['training_time'] for result in results.values()]\n",
    "axes[1, 1].bar(model_names, training_times)\n",
    "axes[1, 1].set_title('Temps d\\'entra√Ænement')\n",
    "axes[1, 1].set_ylabel('Temps (secondes)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f98f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse d√©taill√©e des pr√©dictions du meilleur mod√®le\n",
    "best_result = results[best_model_name]\n",
    "y_pred_test = best_result['y_pred_test']\n",
    "\n",
    "# Visualisation des pr√©dictions\n",
    "n_samples_to_plot = min(100, len(data['y_test']))\n",
    "indices = np.arange(n_samples_to_plot)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Pr√©dictions vs r√©alit√© (√©chantillon)\n",
    "axes[0, 0].plot(indices, data['y_test'][:n_samples_to_plot, 0], 'b-', label='R√©el', alpha=0.7)\n",
    "axes[0, 0].plot(indices, y_pred_test[:n_samples_to_plot, 0], 'r-', label='Pr√©dit', alpha=0.7)\n",
    "axes[0, 0].set_title(f'{best_model_name} - Pr√©dictions vs R√©alit√© (premier pas de temps)')\n",
    "axes[0, 0].set_xlabel('√âchantillon')\n",
    "axes[0, 0].set_ylabel('Valeur normalis√©e')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Scatter plot - corr√©lation\n",
    "axes[0, 1].scatter(data['y_test'][:, 0], y_pred_test[:, 0], alpha=0.5)\n",
    "axes[0, 1].plot([data['y_test'][:, 0].min(), data['y_test'][:, 0].max()], \n",
    "                [data['y_test'][:, 0].min(), data['y_test'][:, 0].max()], 'r--')\n",
    "axes[0, 1].set_title(f'{best_model_name} - Corr√©lation Pr√©dictions/R√©alit√©')\n",
    "axes[0, 1].set_xlabel('Valeurs r√©elles')\n",
    "axes[0, 1].set_ylabel('Valeurs pr√©dites')\n",
    "\n",
    "# Distribution des erreurs\n",
    "errors = y_pred_test[:, 0] - data['y_test'][:, 0]\n",
    "axes[1, 0].hist(errors, bins=50, alpha=0.7, density=True)\n",
    "axes[1, 0].set_title(f'{best_model_name} - Distribution des erreurs')\n",
    "axes[1, 0].set_xlabel('Erreur (pr√©dit - r√©el)')\n",
    "axes[1, 0].set_ylabel('Densit√©')\n",
    "\n",
    "# Erreurs absolues dans le temps\n",
    "abs_errors = np.abs(errors)\n",
    "axes[1, 1].plot(indices, abs_errors[:n_samples_to_plot])\n",
    "axes[1, 1].set_title(f'{best_model_name} - Erreurs absolues dans le temps')\n",
    "axes[1, 1].set_xlabel('√âchantillon')\n",
    "axes[1, 1].set_ylabel('Erreur absolue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques des erreurs\n",
    "print(f\"\\nüìä Statistiques des erreurs ({best_model_name}):\")\n",
    "print(f\"  Erreur moyenne: {np.mean(errors):.6f}\")\n",
    "print(f\"  Erreur absolue moyenne: {np.mean(abs_errors):.6f}\")\n",
    "print(f\"  √âcart-type des erreurs: {np.std(errors):.6f}\")\n",
    "print(f\"  Erreur max: {np.max(abs_errors):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671f6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de signification statistique des diff√©rences de performance\n",
    "from scipy import stats\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTS STATISTIQUES DE COMPARAISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Comparaison SigTKAN vs baselines\n",
    "if 'SigTKAN_Manual' in results:\n",
    "    sigtkan_errors = np.abs(results['SigTKAN_Manual']['y_pred_test'][:, 0] - data['y_test'][:, 0])\n",
    "    \n",
    "    for baseline_name in ['LSTM_Baseline', 'GRU_Baseline']:\n",
    "        if baseline_name in results:\n",
    "            baseline_errors = np.abs(results[baseline_name]['y_pred_test'][:, 0] - data['y_test'][:, 0])\n",
    "            \n",
    "            # Test de Wilcoxon (non-param√©trique)\n",
    "            statistic, p_value = stats.wilcoxon(sigtkan_errors, baseline_errors, alternative='two-sided')\n",
    "            \n",
    "            print(f\"\\nTest de Wilcoxon: SigTKAN_Manual vs {baseline_name}\")\n",
    "            print(f\"  Statistique: {statistic:.4f}\")\n",
    "            print(f\"  p-value: {p_value:.6f}\")\n",
    "            \n",
    "            if p_value < 0.05:\n",
    "                if np.mean(sigtkan_errors) < np.mean(baseline_errors):\n",
    "                    print(f\"  ‚Üí SigTKAN_Manual est significativement MEILLEUR que {baseline_name}\")\n",
    "                else:\n",
    "                    print(f\"  ‚Üí SigTKAN_Manual est significativement MOINS BON que {baseline_name}\")\n",
    "            else:\n",
    "                print(f\"  ‚Üí Pas de diff√©rence significative entre SigTKAN_Manual et {baseline_name}\")\n",
    "\n",
    "# Analyse des temps de convergence\n",
    "print(f\"\\nüìà ANALYSE DE LA CONVERGENCE:\")\n",
    "for model_name, result in results.items():\n",
    "    if 'history' in result:\n",
    "        history = result['history']\n",
    "        val_losses = history.history['val_loss']\n",
    "        \n",
    "        # Trouver l'√©poque de meilleure performance\n",
    "        best_epoch = np.argmin(val_losses)\n",
    "        min_val_loss = val_losses[best_epoch]\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  Meilleure √©poque: {best_epoch + 1}\")\n",
    "        print(f\"  Meilleure val_loss: {min_val_loss:.6f}\")\n",
    "        print(f\"  Nombre total d'√©poques: {len(val_losses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce631e",
   "metadata": {},
   "source": [
    "## Conclusions et Analyse\n",
    "\n",
    "### Objectifs de l'exp√©rience\n",
    "Cette exp√©rience avait pour but de tester si l'int√©gration des signatures dans TKAN (SigTKAN) am√©liore les performances pr√©dictives par rapport aux mod√®les de r√©f√©rence (LSTM, GRU).\n",
    "\n",
    "### Impl√©mentation manuelle\n",
    "- ‚úÖ **SigTKAN avec boucle manuelle**: Impl√©mentation r√©ussie sans h√©riter de la classe RNN de Keras\n",
    "- ‚úÖ **Int√©gration des signatures**: Utilisation de transformations de signatures pour enrichir l'information temporelle\n",
    "- ‚úÖ **Comparaison √©quitable**: M√™me architecture de sortie pour tous les mod√®les\n",
    "\n",
    "### M√©triques de performance\n",
    "Les mod√®les ont √©t√© √©valu√©s sur:\n",
    "- **MSE (Mean Squared Error)**: Erreur quadratique moyenne\n",
    "- **MAE (Mean Absolute Error)**: Erreur absolue moyenne  \n",
    "- **R¬≤ (Coefficient de d√©termination)**: Qualit√© de l'ajustement\n",
    "- **Temps d'entra√Ænement**: Efficacit√© computationnelle\n",
    "\n",
    "### Points cl√©s observ√©s\n",
    "1. **Complexit√© du mod√®le**: SigTKAN est plus complexe avec les transformations de signatures\n",
    "2. **Convergence**: Analyse des courbes de loss pour comprendre la stabilit√© d'entra√Ænement\n",
    "3. **G√©n√©ralisation**: Comparaison des performances train vs test\n",
    "\n",
    "### Prochaines √©tapes possibles\n",
    "- Test sur d'autres datasets (volatilit√©, autres actifs financiers)\n",
    "- Optimisation des hyperparam√®tres (sig_level, architecture des sous-couches KAN)\n",
    "- Analyse de l'impact de diff√©rents niveaux de signature\n",
    "- Comparaison avec d'autres architectures avanc√©es (Transformers, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des r√©sultats pour analyse ult√©rieure\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Sauvegarder les m√©triques et configurations\n",
    "results_summary = {}\n",
    "for model_name, result in results.items():\n",
    "    results_summary[model_name] = {\n",
    "        'metrics': result['metrics'],\n",
    "        'training_time': result['training_time'],\n",
    "        'model_params': result['model'].count_params()\n",
    "    }\n",
    "\n",
    "# Sauvegarder en JSON\n",
    "with open('sigtkan_manual_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "# Sauvegarder les mod√®les (seulement le meilleur pour √©conomiser l'espace)\n",
    "best_result['model'].save('best_sigtkan_manual_model.keras')\n",
    "\n",
    "print(\"‚úÖ R√©sultats sauvegard√©s:\")\n",
    "print(\"  - sigtkan_manual_results.json (m√©triques)\")\n",
    "print(\"  - best_sigtkan_manual_model.keras (meilleur mod√®le)\")\n",
    "print(f\"\\nüéØ Exp√©rience termin√©e avec succ√®s!\")\n",
    "print(f\"   Meilleur mod√®le: {best_model_name}\")\n",
    "print(f\"   Test R¬≤: {results[best_model_name]['metrics']['test_r2']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
