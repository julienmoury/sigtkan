{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a88a67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['pip', 'install', 'sklearn'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL'] = 'True'\n",
    "import subprocess\n",
    "subprocess.run(['pip', 'install', 'sklearn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f3a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastparquet as fp\n",
    "import time\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import tensorflow as tf\n",
    "keras.utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c50578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sigtkan import SigTKAN\n",
    "from tkan import TKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32a454e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC</th>\n",
       "      <th>ADA</th>\n",
       "      <th>XMR</th>\n",
       "      <th>EOS</th>\n",
       "      <th>CHZ</th>\n",
       "      <th>MATIC</th>\n",
       "      <th>TRX</th>\n",
       "      <th>ENJ</th>\n",
       "      <th>FTM</th>\n",
       "      <th>BNB</th>\n",
       "      <th>XLM</th>\n",
       "      <th>BUSD</th>\n",
       "      <th>ATOM</th>\n",
       "      <th>LTC</th>\n",
       "      <th>LINK</th>\n",
       "      <th>ETC</th>\n",
       "      <th>ETH</th>\n",
       "      <th>XRP</th>\n",
       "      <th>BCH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>3.675857e+06</td>\n",
       "      <td>38189.176211</td>\n",
       "      <td>45395.983051</td>\n",
       "      <td>9.477858e+04</td>\n",
       "      <td>817.146319</td>\n",
       "      <td>31003.791035</td>\n",
       "      <td>481993.354990</td>\n",
       "      <td>15241.945783</td>\n",
       "      <td>1165.788613</td>\n",
       "      <td>8.498617e+05</td>\n",
       "      <td>9460.819556</td>\n",
       "      <td>1.352376e+04</td>\n",
       "      <td>31986.972694</td>\n",
       "      <td>1.165827e+05</td>\n",
       "      <td>2.428117e+04</td>\n",
       "      <td>5.648840e+04</td>\n",
       "      <td>1.000930e+06</td>\n",
       "      <td>2.579254e+05</td>\n",
       "      <td>1.782587e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:00:00</th>\n",
       "      <td>6.365953e+06</td>\n",
       "      <td>51357.010954</td>\n",
       "      <td>33483.951528</td>\n",
       "      <td>5.932921e+05</td>\n",
       "      <td>886.460339</td>\n",
       "      <td>84465.335718</td>\n",
       "      <td>533668.554562</td>\n",
       "      <td>11896.843688</td>\n",
       "      <td>413.844612</td>\n",
       "      <td>7.405759e+05</td>\n",
       "      <td>37141.909518</td>\n",
       "      <td>2.531605e+04</td>\n",
       "      <td>81777.666046</td>\n",
       "      <td>2.830715e+05</td>\n",
       "      <td>5.119098e+04</td>\n",
       "      <td>1.821021e+05</td>\n",
       "      <td>1.474278e+06</td>\n",
       "      <td>4.520609e+05</td>\n",
       "      <td>6.153210e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 02:00:00</th>\n",
       "      <td>4.736719e+06</td>\n",
       "      <td>36164.263914</td>\n",
       "      <td>15732.553860</td>\n",
       "      <td>2.667326e+05</td>\n",
       "      <td>1819.795050</td>\n",
       "      <td>113379.718506</td>\n",
       "      <td>387049.986770</td>\n",
       "      <td>30109.770521</td>\n",
       "      <td>3559.965968</td>\n",
       "      <td>1.039091e+06</td>\n",
       "      <td>16878.822627</td>\n",
       "      <td>1.390886e+04</td>\n",
       "      <td>195731.175551</td>\n",
       "      <td>2.402871e+05</td>\n",
       "      <td>2.872176e+04</td>\n",
       "      <td>1.340634e+05</td>\n",
       "      <td>9.940256e+05</td>\n",
       "      <td>4.414948e+05</td>\n",
       "      <td>2.215356e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 03:00:00</th>\n",
       "      <td>5.667367e+06</td>\n",
       "      <td>24449.953815</td>\n",
       "      <td>25751.054662</td>\n",
       "      <td>1.245166e+05</td>\n",
       "      <td>2979.655803</td>\n",
       "      <td>41771.707995</td>\n",
       "      <td>450772.139235</td>\n",
       "      <td>6732.833578</td>\n",
       "      <td>4076.415482</td>\n",
       "      <td>4.975018e+05</td>\n",
       "      <td>9049.223394</td>\n",
       "      <td>2.251969e+04</td>\n",
       "      <td>120113.343316</td>\n",
       "      <td>1.613043e+05</td>\n",
       "      <td>2.959622e+04</td>\n",
       "      <td>1.310942e+05</td>\n",
       "      <td>6.473610e+05</td>\n",
       "      <td>1.886061e+05</td>\n",
       "      <td>3.971860e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>3.379094e+06</td>\n",
       "      <td>44502.669843</td>\n",
       "      <td>62955.628253</td>\n",
       "      <td>4.218197e+05</td>\n",
       "      <td>1023.388675</td>\n",
       "      <td>22254.756114</td>\n",
       "      <td>284788.973752</td>\n",
       "      <td>846.938455</td>\n",
       "      <td>633.367505</td>\n",
       "      <td>4.751285e+05</td>\n",
       "      <td>7254.260203</td>\n",
       "      <td>1.122460e+04</td>\n",
       "      <td>19989.169106</td>\n",
       "      <td>2.214516e+05</td>\n",
       "      <td>5.451437e+04</td>\n",
       "      <td>1.349371e+05</td>\n",
       "      <td>4.430067e+05</td>\n",
       "      <td>2.279373e+05</td>\n",
       "      <td>3.164991e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21 15:00:00</th>\n",
       "      <td>1.255210e+07</td>\n",
       "      <td>470590.372121</td>\n",
       "      <td>42760.927068</td>\n",
       "      <td>7.453124e+05</td>\n",
       "      <td>13246.215433</td>\n",
       "      <td>194642.829145</td>\n",
       "      <td>350917.288805</td>\n",
       "      <td>11395.449868</td>\n",
       "      <td>3316.339995</td>\n",
       "      <td>1.924501e+06</td>\n",
       "      <td>413944.202762</td>\n",
       "      <td>5.766766e+05</td>\n",
       "      <td>136528.213153</td>\n",
       "      <td>5.953967e+05</td>\n",
       "      <td>2.351074e+05</td>\n",
       "      <td>1.635402e+06</td>\n",
       "      <td>1.511907e+06</td>\n",
       "      <td>9.031691e+05</td>\n",
       "      <td>1.614753e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21 16:00:00</th>\n",
       "      <td>1.343373e+07</td>\n",
       "      <td>961845.809967</td>\n",
       "      <td>113709.479837</td>\n",
       "      <td>1.269031e+06</td>\n",
       "      <td>3692.115542</td>\n",
       "      <td>359433.587696</td>\n",
       "      <td>422347.988487</td>\n",
       "      <td>5052.336237</td>\n",
       "      <td>8456.993069</td>\n",
       "      <td>1.306569e+06</td>\n",
       "      <td>830123.292453</td>\n",
       "      <td>3.433625e+05</td>\n",
       "      <td>224934.146373</td>\n",
       "      <td>9.369866e+05</td>\n",
       "      <td>4.863213e+05</td>\n",
       "      <td>2.595147e+06</td>\n",
       "      <td>3.791875e+06</td>\n",
       "      <td>1.689575e+06</td>\n",
       "      <td>2.933687e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21 17:00:00</th>\n",
       "      <td>8.343923e+06</td>\n",
       "      <td>343709.850786</td>\n",
       "      <td>42191.566063</td>\n",
       "      <td>4.855322e+05</td>\n",
       "      <td>42834.106271</td>\n",
       "      <td>136314.391155</td>\n",
       "      <td>351140.663827</td>\n",
       "      <td>5293.137970</td>\n",
       "      <td>11741.040433</td>\n",
       "      <td>1.065739e+06</td>\n",
       "      <td>347330.782839</td>\n",
       "      <td>1.534735e+05</td>\n",
       "      <td>563745.606195</td>\n",
       "      <td>2.516371e+05</td>\n",
       "      <td>3.994359e+05</td>\n",
       "      <td>6.810294e+05</td>\n",
       "      <td>1.449803e+06</td>\n",
       "      <td>6.444043e+05</td>\n",
       "      <td>8.640450e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21 18:00:00</th>\n",
       "      <td>7.122794e+06</td>\n",
       "      <td>329554.903526</td>\n",
       "      <td>52364.406501</td>\n",
       "      <td>6.496494e+05</td>\n",
       "      <td>29860.482940</td>\n",
       "      <td>329643.707813</td>\n",
       "      <td>356885.767760</td>\n",
       "      <td>5622.020669</td>\n",
       "      <td>36002.529422</td>\n",
       "      <td>9.230081e+05</td>\n",
       "      <td>209088.135394</td>\n",
       "      <td>1.478474e+06</td>\n",
       "      <td>277002.105035</td>\n",
       "      <td>4.956549e+05</td>\n",
       "      <td>3.365914e+05</td>\n",
       "      <td>7.091066e+05</td>\n",
       "      <td>9.606181e+05</td>\n",
       "      <td>5.658003e+05</td>\n",
       "      <td>8.713010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21 19:00:00</th>\n",
       "      <td>3.283562e+07</td>\n",
       "      <td>829409.178856</td>\n",
       "      <td>146513.098683</td>\n",
       "      <td>2.166948e+06</td>\n",
       "      <td>24900.553291</td>\n",
       "      <td>386377.960136</td>\n",
       "      <td>785236.921293</td>\n",
       "      <td>20884.321104</td>\n",
       "      <td>19669.649861</td>\n",
       "      <td>2.372031e+06</td>\n",
       "      <td>506624.749138</td>\n",
       "      <td>4.974161e+05</td>\n",
       "      <td>253850.223766</td>\n",
       "      <td>1.333555e+06</td>\n",
       "      <td>1.175888e+06</td>\n",
       "      <td>1.463391e+06</td>\n",
       "      <td>3.494803e+06</td>\n",
       "      <td>1.970993e+06</td>\n",
       "      <td>2.821026e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              BTC            ADA            XMR           EOS  \\\n",
       "group                                                                           \n",
       "2020-01-01 00:00:00  3.675857e+06   38189.176211   45395.983051  9.477858e+04   \n",
       "2020-01-01 01:00:00  6.365953e+06   51357.010954   33483.951528  5.932921e+05   \n",
       "2020-01-01 02:00:00  4.736719e+06   36164.263914   15732.553860  2.667326e+05   \n",
       "2020-01-01 03:00:00  5.667367e+06   24449.953815   25751.054662  1.245166e+05   \n",
       "2020-01-01 04:00:00  3.379094e+06   44502.669843   62955.628253  4.218197e+05   \n",
       "...                           ...            ...            ...           ...   \n",
       "2020-01-21 15:00:00  1.255210e+07  470590.372121   42760.927068  7.453124e+05   \n",
       "2020-01-21 16:00:00  1.343373e+07  961845.809967  113709.479837  1.269031e+06   \n",
       "2020-01-21 17:00:00  8.343923e+06  343709.850786   42191.566063  4.855322e+05   \n",
       "2020-01-21 18:00:00  7.122794e+06  329554.903526   52364.406501  6.496494e+05   \n",
       "2020-01-21 19:00:00  3.283562e+07  829409.178856  146513.098683  2.166948e+06   \n",
       "\n",
       "                              CHZ          MATIC            TRX           ENJ  \\\n",
       "group                                                                           \n",
       "2020-01-01 00:00:00    817.146319   31003.791035  481993.354990  15241.945783   \n",
       "2020-01-01 01:00:00    886.460339   84465.335718  533668.554562  11896.843688   \n",
       "2020-01-01 02:00:00   1819.795050  113379.718506  387049.986770  30109.770521   \n",
       "2020-01-01 03:00:00   2979.655803   41771.707995  450772.139235   6732.833578   \n",
       "2020-01-01 04:00:00   1023.388675   22254.756114  284788.973752    846.938455   \n",
       "...                           ...            ...            ...           ...   \n",
       "2020-01-21 15:00:00  13246.215433  194642.829145  350917.288805  11395.449868   \n",
       "2020-01-21 16:00:00   3692.115542  359433.587696  422347.988487   5052.336237   \n",
       "2020-01-21 17:00:00  42834.106271  136314.391155  351140.663827   5293.137970   \n",
       "2020-01-21 18:00:00  29860.482940  329643.707813  356885.767760   5622.020669   \n",
       "2020-01-21 19:00:00  24900.553291  386377.960136  785236.921293  20884.321104   \n",
       "\n",
       "                              FTM           BNB            XLM          BUSD  \\\n",
       "group                                                                          \n",
       "2020-01-01 00:00:00   1165.788613  8.498617e+05    9460.819556  1.352376e+04   \n",
       "2020-01-01 01:00:00    413.844612  7.405759e+05   37141.909518  2.531605e+04   \n",
       "2020-01-01 02:00:00   3559.965968  1.039091e+06   16878.822627  1.390886e+04   \n",
       "2020-01-01 03:00:00   4076.415482  4.975018e+05    9049.223394  2.251969e+04   \n",
       "2020-01-01 04:00:00    633.367505  4.751285e+05    7254.260203  1.122460e+04   \n",
       "...                           ...           ...            ...           ...   \n",
       "2020-01-21 15:00:00   3316.339995  1.924501e+06  413944.202762  5.766766e+05   \n",
       "2020-01-21 16:00:00   8456.993069  1.306569e+06  830123.292453  3.433625e+05   \n",
       "2020-01-21 17:00:00  11741.040433  1.065739e+06  347330.782839  1.534735e+05   \n",
       "2020-01-21 18:00:00  36002.529422  9.230081e+05  209088.135394  1.478474e+06   \n",
       "2020-01-21 19:00:00  19669.649861  2.372031e+06  506624.749138  4.974161e+05   \n",
       "\n",
       "                              ATOM           LTC          LINK           ETC  \\\n",
       "group                                                                          \n",
       "2020-01-01 00:00:00   31986.972694  1.165827e+05  2.428117e+04  5.648840e+04   \n",
       "2020-01-01 01:00:00   81777.666046  2.830715e+05  5.119098e+04  1.821021e+05   \n",
       "2020-01-01 02:00:00  195731.175551  2.402871e+05  2.872176e+04  1.340634e+05   \n",
       "2020-01-01 03:00:00  120113.343316  1.613043e+05  2.959622e+04  1.310942e+05   \n",
       "2020-01-01 04:00:00   19989.169106  2.214516e+05  5.451437e+04  1.349371e+05   \n",
       "...                            ...           ...           ...           ...   \n",
       "2020-01-21 15:00:00  136528.213153  5.953967e+05  2.351074e+05  1.635402e+06   \n",
       "2020-01-21 16:00:00  224934.146373  9.369866e+05  4.863213e+05  2.595147e+06   \n",
       "2020-01-21 17:00:00  563745.606195  2.516371e+05  3.994359e+05  6.810294e+05   \n",
       "2020-01-21 18:00:00  277002.105035  4.956549e+05  3.365914e+05  7.091066e+05   \n",
       "2020-01-21 19:00:00  253850.223766  1.333555e+06  1.175888e+06  1.463391e+06   \n",
       "\n",
       "                              ETH           XRP           BCH  \n",
       "group                                                          \n",
       "2020-01-01 00:00:00  1.000930e+06  2.579254e+05  1.782587e+05  \n",
       "2020-01-01 01:00:00  1.474278e+06  4.520609e+05  6.153210e+05  \n",
       "2020-01-01 02:00:00  9.940256e+05  4.414948e+05  2.215356e+05  \n",
       "2020-01-01 03:00:00  6.473610e+05  1.886061e+05  3.971860e+05  \n",
       "2020-01-01 04:00:00  4.430067e+05  2.279373e+05  3.164991e+05  \n",
       "...                           ...           ...           ...  \n",
       "2020-01-21 15:00:00  1.511907e+06  9.031691e+05  1.614753e+06  \n",
       "2020-01-21 16:00:00  3.791875e+06  1.689575e+06  2.933687e+06  \n",
       "2020-01-21 17:00:00  1.449803e+06  6.444043e+05  8.640450e+05  \n",
       "2020-01-21 18:00:00  9.606181e+05  5.658003e+05  8.713010e+05  \n",
       "2020-01-21 19:00:00  3.494803e+06  1.970993e+06  2.821026e+06  \n",
       "\n",
       "[500 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet('data.parquet')\n",
    "df = df[(df.index >= pd.Timestamp('2020-01-01')) & (df.index < pd.Timestamp('2023-01-01'))]\n",
    "assets = ['BTC', 'ETH', 'ADA', 'XMR', 'EOS', 'MATIC', 'TRX', 'FTM', 'BNB', 'XLM', 'ENJ', 'CHZ', 'BUSD', 'ATOM', 'LINK', 'ETC', 'XRP', 'BCH', 'LTC']\n",
    "df = df[[c for c in df.columns if 'quote asset volume' in c and any(asset in c for asset in assets)]]\n",
    "df.columns = [c.replace(' quote asset volume', '') for c in df.columns]\n",
    "df = df.head(500)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79b0b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler:\n",
    "    def __init__(self, feature_axis=None, minmax_range=(0, 1)):\n",
    "        \"\"\"\n",
    "        Initialize the MinMaxScaler.\n",
    "        Args:\n",
    "        feature_axis (int, optional): The axis that represents the feature dimension if applicable.\n",
    "                                      Use only for 3D data to specify which axis is the feature axis.\n",
    "                                      Default is None, automatically managed based on data dimensions.\n",
    "        \"\"\"\n",
    "        self.feature_axis = feature_axis\n",
    "        self.min_ = None\n",
    "        self.max_ = None\n",
    "        self.scale_ = None\n",
    "        self.minmax_range = minmax_range # Default range for scaling (min, max)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the scaler to the data based on its dimensionality.\n",
    "        Args:\n",
    "        X (np.array): The data to fit the scaler on.\n",
    "        \"\"\"\n",
    "        if X.ndim == 3 and self.feature_axis is not None:  # 3D data\n",
    "            axis = tuple(i for i in range(X.ndim) if i != self.feature_axis)\n",
    "            self.min_ = np.min(X, axis=axis)\n",
    "            self.max_ = np.max(X, axis=axis)\n",
    "        elif X.ndim == 2:  # 2D data\n",
    "            self.min_ = np.min(X, axis=0)\n",
    "            self.max_ = np.max(X, axis=0)\n",
    "        elif X.ndim == 1:  # 1D data\n",
    "            self.min_ = np.min(X)\n",
    "            self.max_ = np.max(X)\n",
    "        else:\n",
    "            raise ValueError(\"Data must be 1D, 2D, or 3D.\")\n",
    "\n",
    "        self.scale_ = self.max_ - self.min_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the data using the fitted scaler.\n",
    "        Args:\n",
    "        X (np.array): The data to transform.\n",
    "        Returns:\n",
    "        np.array: The scaled data.\n",
    "        \"\"\"\n",
    "        X_scaled = (X - self.min_) / self.scale_\n",
    "        X_scaled = X_scaled * (self.minmax_range[1] - self.minmax_range[0]) + self.minmax_range[0]\n",
    "        return X_scaled\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fit to data, then transform it.\n",
    "        Args:\n",
    "        X (np.array): The data to fit and transform.\n",
    "        Returns:\n",
    "        np.array: The scaled data.\n",
    "        \"\"\"\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def inverse_transform(self, X_scaled):\n",
    "        \"\"\"\n",
    "        Inverse transform the scaled data to original data.\n",
    "        Args:\n",
    "        X_scaled (np.array): The scaled data to inverse transform.\n",
    "        Returns:\n",
    "        np.array: The original data scale.\n",
    "        \"\"\"\n",
    "        X = (X_scaled - self.minmax_range[0]) / (self.minmax_range[1] - self.minmax_range[0])\n",
    "        X = X * self.scale_ + self.min_\n",
    "        return X\n",
    "\n",
    "def generate_data(df, sequence_length, n_ahead = 1):\n",
    "    #Case without known inputs\n",
    "    scaler_df = df.copy().shift(n_ahead).rolling(24 * 14).median()\n",
    "    tmp_df = df.copy() / scaler_df\n",
    "    tmp_df = tmp_df.iloc[24 * 14 + n_ahead:].fillna(0.)\n",
    "    scaler_df = scaler_df.iloc[24 * 14 + n_ahead:].fillna(0.)\n",
    "    def prepare_sequences(df, scaler_df, n_history, n_future):\n",
    "        X, y, y_scaler = [], [], []\n",
    "        num_features = df.shape[1]\n",
    "        \n",
    "        # Iterate through the DataFrame to create sequences\n",
    "        for i in range(n_history, len(df) - n_future + 1):\n",
    "            # Extract the sequence of past observations\n",
    "            X.append(df.iloc[i - n_history:i].values)\n",
    "            # Extract the future values of the first column\n",
    "            y.append(df.iloc[i:i + n_future,0:1].values)\n",
    "            y_scaler.append(scaler_df.iloc[i:i + n_future,0:1].values)\n",
    "        \n",
    "        X, y, y_scaler = np.array(X), np.array(y), np.array(y_scaler)\n",
    "        return X, y, y_scaler\n",
    "    \n",
    "    # Prepare sequences\n",
    "    X, y, y_scaler = prepare_sequences(tmp_df, scaler_df, sequence_length, n_ahead)\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    train_test_separation = int(len(X) * 0.8)\n",
    "    X_train_unscaled, X_test_unscaled = X[:train_test_separation], X[train_test_separation:]\n",
    "    y_train_unscaled, y_test_unscaled = y[:train_test_separation], y[train_test_separation:]\n",
    "    y_scaler_train, y_scaler_test = y_scaler[:train_test_separation], y_scaler[train_test_separation:]\n",
    "    \n",
    "    # Generate the data\n",
    "    X_scaler = MinMaxScaler(feature_axis=2)\n",
    "    X_train = X_scaler.fit_transform(X_train_unscaled)\n",
    "    X_test = X_scaler.transform(X_test_unscaled)\n",
    "    \n",
    "    y_scaler = MinMaxScaler(feature_axis=2)\n",
    "    y_train = y_scaler.fit_transform(y_train_unscaled)\n",
    "    y_test = y_scaler.transform(y_test_unscaled)\n",
    "    \n",
    "    y_train = y_train.reshape(y_train.shape[0], -1) \n",
    "    y_test = y_test.reshape(y_test.shape[0], -1)\n",
    "    return X_scaler, X_train, X_test, X_train_unscaled, X_test_unscaled, y_scaler, y_train, y_test, y_train_unscaled, y_test_unscaled, y_scaler_train, y_scaler_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa901df",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = lambda : tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00001,    \n",
    "    patience=6,         \n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=3, \n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "lr_callback = lambda : tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.25,\n",
    "    patience=3,\n",
    "    mode=\"min\",\n",
    "    min_delta=0.0001,  \n",
    "    min_lr=0.000025,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = lambda : [early_stopping_callback(), lr_callback(), tf.keras.callbacks.TerminateOnNaN()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32621fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TKAN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"TKAN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tkan (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TKAN</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,980</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tkan_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TKAN</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tkan (\u001b[38;5;33mTKAN\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m41,980\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ tkan_1 (\u001b[38;5;33mTKAN\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m67,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,981</span> (429.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,981\u001b[0m (429.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,581</span> (428.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,581\u001b[0m (428.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> (1.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m400\u001b[0m (1.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: early stopping\n",
      "17.36777663230896 -0.10719409345978281\n",
      "Epoch 15: early stopping\n",
      "11.350396633148193 -0.11455709706362804\n",
      "Epoch 8: early stopping\n",
      "9.629224061965942 -8.517273963767057\n",
      "Epoch 6: early stopping\n",
      "9.54746127128601 -2.005832781393044\n",
      "Epoch 14: early stopping\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000208A22A5D00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "11.032715082168579 -0.18755474105340197\n",
      "Epoch 4: early stopping\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000208FBAE6FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "9.049691438674927 -6.479782882479294\n",
      "WARNING:tensorflow:5 out of the last 37 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x000002091D70F6A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 9: early stopping\n",
      "9.39536428451538 -7.374046037513969\n",
      "Epoch 33: early stopping\n",
      "15.865599155426025 -1.8811576110244665\n",
      "Epoch 4: early stopping\n",
      "8.529558420181274 -10.042124990305703\n",
      "WARNING:tensorflow:5 out of the last 75 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x00000209782B0720> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 15: early stopping\n",
      "11.783188104629517 -0.34741692713630057\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SigTKAN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SigTKAN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sig_tkan (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SigTKAN</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,945</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sig_tkan_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SigTKAN</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,045</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sig_tkan (\u001b[38;5;33mSigTKAN\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │         \u001b[38;5;34m1,945\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sig_tkan_1 (\u001b[38;5;33mSigTKAN\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,045\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,091</span> (47.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,091\u001b[0m (47.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,091</span> (47.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,091\u001b[0m (47.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m     model.summary()\n\u001b[32m     55\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_MAX_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m end_time = time.time()\n\u001b[32m     58\u001b[39m time_results[model_id][n_ahead].append(end_time - start_time)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:889\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    886\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    887\u001b[39m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[32m    888\u001b[39m   initializers = []\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    891\u001b[39m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[32m    892\u001b[39m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[32m    893\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:696\u001b[39m, in \u001b[36mFunction._initialize\u001b[39m\u001b[34m(self, args, kwds, add_initializers_to)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28mself\u001b[39m._variable_creation_config = \u001b[38;5;28mself\u001b[39m._generate_scoped_tracing_options(\n\u001b[32m    692\u001b[39m     variable_capturing_scope,\n\u001b[32m    693\u001b[39m     tracing_compilation.ScopeType.VARIABLE_CREATION,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_creator_scope\u001b[39m(*unused_args, **unused_kwds):\n\u001b[32m    701\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:339\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[32m    338\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph artifact\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools.partial):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:133\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_execution == \u001b[32m1\u001b[39m:\n\u001b[32m    132\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.experimental.Optional.from_value(\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m             \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m         )\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[32m    137\u001b[39m     empty_outputs = tf.experimental.Optional.empty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:906\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[32m    903\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    904\u001b[39m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[32m    905\u001b[39m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    910\u001b[39m   bound_args = \u001b[38;5;28mself\u001b[39m._concrete_variable_creation_fn.function_type.bind(\n\u001b[32m    911\u001b[39m       *args, **kwds\n\u001b[32m    912\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:283\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    282\u001b[39m   target_func_type = lookup_func_type\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m concrete_function = \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    288\u001b[39m   tracing_options.function_cache.add(\n\u001b[32m    289\u001b[39m       concrete_function, current_func_context\n\u001b[32m    290\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:310\u001b[39m, in \u001b[36m_create_concrete_function\u001b[39m\u001b[34m(function_type, type_context, func_graph, tracing_options)\u001b[39m\n\u001b[32m    303\u001b[39m   placeholder_bound_args = function_type.placeholder_arguments(\n\u001b[32m    304\u001b[39m       placeholder_context\n\u001b[32m    305\u001b[39m   )\n\u001b[32m    307\u001b[39m disable_acd = tracing_options.attributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options.attributes.get(\n\u001b[32m    308\u001b[39m     attributes_lib.DISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    309\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m traced_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_type_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m transform.apply_func_graph_transforms(traced_func_graph)\n\u001b[32m    324\u001b[39m graph_capture_container = traced_func_graph.function_captures\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:599\u001b[39m, in \u001b[36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m default_graph._variable_creator_scope(scope, priority=\u001b[32m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    596\u001b[39m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[32m    597\u001b[39m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[32m    598\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     out = \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    600\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\autograph_util.py:41\u001b[39m, in \u001b[36mpy_func_from_autograph.<locals>.autograph_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m     51\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mag_error_metadata\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[39m, in \u001b[36mconverted_call\u001b[39m\u001b[34m(f, args, kwargs, caller_fn_scope, options)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conversion.is_in_allowlist_cache(f, options):\n\u001b[32m    330\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: from cache\u001b[39m\u001b[33m'\u001b[39m, f)\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx.control_status_ctx().status == ag_ctx.Status.DISABLED:\n\u001b[32m    334\u001b[39m   logging.log(\u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m: AutoGraph is disabled in context\u001b[39m\u001b[33m'\u001b[39m, f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[39m, in \u001b[36m_call_unconverted\u001b[39m\u001b[34m(f, args, kwargs, options, update_cache)\u001b[39m\n\u001b[32m    456\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m f.\u001b[34m__self__\u001b[39m.call(args, kwargs)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m f(*args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:114\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;129m@tf\u001b[39m.autograph.experimental.do_not_convert\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mone_step_on_data\u001b[39m(data):\n\u001b[32m    113\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     outputs = reduce_per_replica(\n\u001b[32m    116\u001b[39m         outputs,\n\u001b[32m    117\u001b[39m         \u001b[38;5;28mself\u001b[39m.distribute_strategy,\n\u001b[32m    118\u001b[39m         reduction=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    119\u001b[39m     )\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1673\u001b[39m, in \u001b[36mStrategyBase.run\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1668\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope():\n\u001b[32m   1669\u001b[39m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[32m   1670\u001b[39m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[32m   1671\u001b[39m   fn = autograph.tf_convert(\n\u001b[32m   1672\u001b[39m       fn, autograph_ctx.control_status_ctx(), convert_by_default=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1673\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extended\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3263\u001b[39m, in \u001b[36mStrategyExtendedV1.call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   3261\u001b[39m   kwargs = {}\n\u001b[32m   3262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._container_strategy().scope():\n\u001b[32m-> \u001b[39m\u001b[32m3263\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:4061\u001b[39m, in \u001b[36m_DefaultDistributionExtended._call_for_each_replica\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   4059\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m   4060\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m._container_strategy(), replica_id_in_sync_group=\u001b[32m0\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:643\u001b[39m, in \u001b[36mdo_not_convert.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    642\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:78\u001b[39m, in \u001b[36mTensorFlowTrainer.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trainable_weights:\n\u001b[32m     77\u001b[39m     trainable_weights = \u001b[38;5;28mself\u001b[39m.trainable_weights\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     gradients = \u001b[43mtape\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.apply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, trainable_weights))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1066\u001b[39m, in \u001b[36mGradientTape.gradient\u001b[39m\u001b[34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[39m\n\u001b[32m   1060\u001b[39m   output_gradients = (\n\u001b[32m   1061\u001b[39m       composite_tensor_gradient.get_flat_tensors_for_gradients(\n\u001b[32m   1062\u001b[39m           output_gradients))\n\u001b[32m   1063\u001b[39m   output_gradients = [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops.convert_to_tensor(x)\n\u001b[32m   1064\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m flat_grad = \u001b[43mimperative_grad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent:\n\u001b[32m   1075\u001b[39m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[32m   1076\u001b[39m   \u001b[38;5;28mself\u001b[39m._watched_variables = \u001b[38;5;28mself\u001b[39m._tape.watched_variables()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[39m, in \u001b[36mimperative_grad\u001b[39m\u001b[34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m     64\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     65\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % unconnected_gradients)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:148\u001b[39m, in \u001b[36m_gradient_function\u001b[39m\u001b[34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[39m\n\u001b[32m    146\u001b[39m     gradient_name_scope += forward_pass_name_scope + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(gradient_name_scope):\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, *out_grads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:367\u001b[39m, in \u001b[36m_WhileGrad\u001b[39m\u001b[34m(op, *grads)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# We compute the gradient for the sub-graph between trainable ys and xs\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# with non-None incoming gradients. We later pad the None's to the list of\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# outputs.\u001b[39;00m\n\u001b[32m    364\u001b[39m ys, xs, non_none_grads = \u001b[38;5;28mzip\u001b[39m(*[(y, x, grad) \u001b[38;5;28;01mfor\u001b[39;00m (y, x, grad) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    365\u001b[39m     body_graph.outputs, body_graph.inputs, grads) \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m body_grad_graph, args = \u001b[43m_create_grad_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_none_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_grad_fn_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m body_grad_graph.while_op_needs_rewrite:\n\u001b[32m    372\u001b[39m   \u001b[38;5;66;03m# Modify 'op' to output the intermediate accumulators needed by the grad\u001b[39;00m\n\u001b[32m    373\u001b[39m   \u001b[38;5;66;03m# function.\u001b[39;00m\n\u001b[32m    374\u001b[39m   \u001b[38;5;66;03m# NOTE(skyewm): if there are any active sessions, this modification to `op`\u001b[39;00m\n\u001b[32m    375\u001b[39m   \u001b[38;5;66;03m# may make them unrunnable!\u001b[39;00m\n\u001b[32m    377\u001b[39m   cond_graph.name += \u001b[33m\"\u001b[39m\u001b[33m_rewritten\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:663\u001b[39m, in \u001b[36m_create_grad_func\u001b[39m\u001b[34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations)\u001b[39m\n\u001b[32m    660\u001b[39m args = [counter, maximum_iterations, total_iters] + \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[32m    662\u001b[39m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m grad_func_graph = \u001b[43mfunc_graph_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhile_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mbody_graph_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    676\u001b[39m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[32m    677\u001b[39m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph.captures:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1060\u001b[39m, in \u001b[36mfunc_graph_from_py_func\u001b[39m\u001b[34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[39m\n\u001b[32m   1057\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m   1059\u001b[39m _, original_func = tf_decorator.unwrap(python_func)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m func_outputs = \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[32m   1064\u001b[39m func_outputs = variable_utils.convert_variables_to_tensors(func_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:665\u001b[39m, in \u001b[36m_create_grad_func.<locals>.<lambda>\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    660\u001b[39m args = [counter, maximum_iterations, total_iters] + \u001b[38;5;28mlist\u001b[39m(grads)\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[32m    662\u001b[39m \u001b[38;5;66;03m# `external_captures`.\u001b[39;00m\n\u001b[32m    663\u001b[39m grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[32m    664\u001b[39m     name,\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m *args: \u001b[43m_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody_graph\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    666\u001b[39m     args, {},\n\u001b[32m    667\u001b[39m     func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[32m    668\u001b[39m                                        maximum_iterations, while_op,\n\u001b[32m    669\u001b[39m                                        body_graph_inputs, body_graph_outputs))\n\u001b[32m    671\u001b[39m \u001b[38;5;66;03m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[38;5;66;03m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[38;5;66;03m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    676\u001b[39m \u001b[38;5;66;03m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[32m    677\u001b[39m \u001b[38;5;66;03m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m external_capture, internal_capture \u001b[38;5;129;01min\u001b[39;00m grad_func_graph.captures:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:720\u001b[39m, in \u001b[36m_grad_fn\u001b[39m\u001b[34m(ys, xs, args, func_graph)\u001b[39m\n\u001b[32m    713\u001b[39m grad_ys = args[\u001b[32m3\u001b[39m:]\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[32m    716\u001b[39m \u001b[38;5;66;03m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[38;5;66;03m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[38;5;66;03m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[39;00m\n\u001b[32m    719\u001b[39m \u001b[38;5;66;03m# TODO(srbs): Mark GradientsHelper as public?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m grad_outs = \u001b[43mgradients_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_GradientsHelper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_ys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzero\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[38;5;66;03m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[39;00m\n\u001b[32m    725\u001b[39m \u001b[38;5;66;03m# is a tf.StopGradient in the loop body.\u001b[39;00m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grad_outs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:733\u001b[39m, in \u001b[36m_GradientsHelper\u001b[39m\u001b[34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m src_graph._original_op(op):\n\u001b[32m    729\u001b[39m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[32m    730\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m     in_grads = \u001b[43m_MaybeCompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_scope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    736\u001b[39m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[32m    738\u001b[39m     in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[32m    739\u001b[39m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:365\u001b[39m, in \u001b[36m_MaybeCompile\u001b[39m\u001b[34m(scope, op, func, grad_fn)\u001b[39m\n\u001b[32m    362\u001b[39m     xla_compile = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xla_compile:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exit early\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# together with the non-gradient computation.\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:734\u001b[39m, in \u001b[36m_GradientsHelper.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m src_graph._original_op(op):\n\u001b[32m    729\u001b[39m   \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[32m    730\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m grad_fn:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# functions.\u001b[39;00m\n\u001b[32m    733\u001b[39m     in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m                              \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    735\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    736\u001b[39m     \u001b[38;5;66;03m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;66;03m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[32m    738\u001b[39m     in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[32m    739\u001b[39m                              \u001b[38;5;28;01mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1496\u001b[39m, in \u001b[36m_RealDivGrad\u001b[39m\u001b[34m(op, grad)\u001b[39m\n\u001b[32m   1494\u001b[39m cy = math_ops.conj(op.inputs[\u001b[32m1\u001b[39m])\n\u001b[32m   1495\u001b[39m gx = math_ops.realdiv(grad, cy)\n\u001b[32m-> \u001b[39m\u001b[32m1496\u001b[39m gy = grad * math_ops.realdiv(math_ops.realdiv(\u001b[43m-\u001b[49m\u001b[43mcx\u001b[49m, cy), cy)\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ReduceGradientArgs(x, y, gx, gy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:7033\u001b[39m, in \u001b[36mneg\u001b[39m\u001b[34m(x, name)\u001b[39m\n\u001b[32m   7031\u001b[39m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m   7032\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m7033\u001b[39m   _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7034\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   7036\u001b[39m   _result = _dispatch.dispatch(\n\u001b[32m   7037\u001b[39m         neg, (), \u001b[38;5;28mdict\u001b[39m(x=x, name=name)\n\u001b[32m   7038\u001b[39m       )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    791\u001b[39m must_colocate_inputs = [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def.input_arg, inputs)\n\u001b[32m    792\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m arg.is_ref]\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[32m    794\u001b[39m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[32m    795\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m   op = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[32m    804\u001b[39m outputs = op.outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1011\u001b[39m, in \u001b[36m_WhileBodyGradFuncGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (op_type \u001b[38;5;129;01min\u001b[39;00m optimized_reduction_ops \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    995\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m util.output_all_intermediates() \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    996\u001b[39m     \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28minput\u001b[39m.graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_graph \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    999\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m util.graph_wrapped_for_higher_order_tape_gradients(\n\u001b[32m   1000\u001b[39m         \u001b[38;5;28mself\u001b[39m._forward_graph)):\n\u001b[32m   1001\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._move_op_to_forward_graph(\n\u001b[32m   1002\u001b[39m       op_type,\n\u001b[32m   1003\u001b[39m       inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1008\u001b[39m       op_def=op_def,\n\u001b[32m   1009\u001b[39m       compute_device=compute_device)\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WhileBodyGradFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:612\u001b[39m, in \u001b[36mFuncGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m    610\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m ctxt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ctxt, \u001b[33m\"\u001b[39m\u001b[33mAddValue\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    611\u001b[39m     inp = ctxt.AddValue(inp)\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m   inp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcapture\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m   captured_inputs.append(inp)\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._create_op_internal(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    615\u001b[39m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[32m    616\u001b[39m     compute_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:619\u001b[39m, in \u001b[36mFuncGraph.capture\u001b[39m\u001b[34m(self, tensor, name, shape)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcapture\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, name=\u001b[38;5;28;01mNone\u001b[39;00m, shape=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_function_captures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\core\\function\\capture\\capture_container.py:154\u001b[39m, in \u001b[36mFunctionCaptures.capture_by_value\u001b[39m\u001b[34m(self, graph, tensor, name)\u001b[39m\n\u001b[32m    151\u001b[39m     name = tensor.op.name\n\u001b[32m    152\u001b[39m   \u001b[38;5;66;03m# cond/while graphs override _capture_helper() so cannot call\u001b[39;00m\n\u001b[32m    153\u001b[39m   \u001b[38;5;66;03m# self.create_placeholder_helper() here directly.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_capture_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1174\u001b[39m, in \u001b[36m_WhileBodyGradFuncGraph._capture_helper\u001b[39m\u001b[34m(self, tensor, name)\u001b[39m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_graph.outer_graph.as_default():\n\u001b[32m   1173\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m util.clear_control_inputs():\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     tensor_list = \u001b[43mlist_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_tensor_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_build_accumulator_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[38;5;28mself\u001b[39m.extra_inputs.append(tensor_list)\n\u001b[32m   1181\u001b[39m \u001b[38;5;66;03m# Push the intermediate tensor to the tensor list. This captures\u001b[39;00m\n\u001b[32m   1182\u001b[39m \u001b[38;5;66;03m# `tensor_list`.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\list_ops.py:49\u001b[39m, in \u001b[36mempty_tensor_list\u001b[39m\u001b[34m(element_shape, element_dtype, max_num_elements, name)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_num_elements \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m   max_num_elements = -\u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_list_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_tensor_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_build_element_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_list_ops.py:67\u001b[39m, in \u001b[36mempty_tensor_list\u001b[39m\u001b[34m(element_shape, max_num_elements, element_dtype, name)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[32m     66\u001b[39m element_dtype = _execute.make_type(element_dtype, \u001b[33m\"\u001b[39m\u001b[33melement_dtype\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m _, _, _op, _outputs = \u001b[43m_op_def_library\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEmptyTensorList\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43melement_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_num_elements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m                         \u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43melement_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m _result = _outputs[:]\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _execute.must_record_gradient():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[39m, in \u001b[36m_apply_op_helper\u001b[39m\u001b[34m(op_type_name, name, **keywords)\u001b[39m\n\u001b[32m    791\u001b[39m must_colocate_inputs = [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def.input_arg, inputs)\n\u001b[32m    792\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m arg.is_ref]\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[32m    794\u001b[39m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[32m    795\u001b[39m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m   op = \u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[32m    804\u001b[39m outputs = op.outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:614\u001b[39m, in \u001b[36mFuncGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m    612\u001b[39m   inp = \u001b[38;5;28mself\u001b[39m.capture(inp)\n\u001b[32m    613\u001b[39m   captured_inputs.append(inp)\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2705\u001b[39m, in \u001b[36mGraph._create_op_internal\u001b[39m\u001b[34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[39m\n\u001b[32m   2702\u001b[39m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[32m   2703\u001b[39m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[32m   2704\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mutation_lock():\n\u001b[32m-> \u001b[39m\u001b[32m2705\u001b[39m   ret = \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2706\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2707\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2708\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2709\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2710\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2711\u001b[39m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2712\u001b[39m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2713\u001b[39m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2714\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2715\u001b[39m   \u001b[38;5;28mself\u001b[39m._create_op_helper(ret, compute_device=compute_device)\n\u001b[32m   2716\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1200\u001b[39m, in \u001b[36mOperation.from_node_def\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1197\u001b[39m     control_input_ops.append(control_op)\n\u001b[32m   1199\u001b[39m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1200\u001b[39m c_op = \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m=\u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[38;5;28mself\u001b[39m = Operation(c_op, SymbolicTensor)\n\u001b[32m   1202\u001b[39m \u001b[38;5;28mself\u001b[39m._init(g)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tmont\\Documents\\Cours\\Dauphine\\Machine Learning\\ml_project-1\\.conda\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1057\u001b[39m, in \u001b[36m_create_c_op\u001b[39m\u001b[34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[39m\n\u001b[32m   1053\u001b[39m   pywrap_tf_session.TF_SetAttrValueProto(op_desc, compat.as_str(name),\n\u001b[32m   1054\u001b[39m                                          serialized)\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m   c_op = \u001b[43mpywrap_tf_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m errors.InvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1059\u001b[39m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[32m   1060\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e.message)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def tkan_config(return_sequences):\n",
    "    return {\n",
    "        \"units\": 100,\n",
    "        \"dropout\": 0.0,\n",
    "        \"sub_kan_output_dim\": 20,\n",
    "        \"sub_kan_input_dim\": 20,\n",
    "        \"return_sequences\": return_sequences\n",
    "    }\n",
    "\n",
    "n_aheads = [1]\n",
    "models = [\"TKAN\", \"SigTKAN\"]\n",
    "N_MAX_EPOCHS = 1000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "callbacks = lambda : [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1),\n",
    "    tf.keras.callbacks.TerminateOnNaN()\n",
    "]\n",
    "\n",
    "results = {model: {n_ahead: [] for n_ahead in n_aheads} for model in models}\n",
    "results_rmse = {model: {n_ahead: [] for n_ahead in n_aheads} for model in models}\n",
    "time_results = {model: {n_ahead: [] for n_ahead in n_aheads} for model in models}\n",
    "all_errors = {model: {n_ahead: [] for n_ahead in n_aheads} for model in models}\n",
    "\n",
    "for n_ahead in n_aheads:\n",
    "    sequence_length = max(45, 5 * n_ahead)\n",
    "    X_scaler, X_train, X_test, X_train_unscaled, X_test_unscaled, y_scaler, y_train, y_test, y_train_unscaled, y_test_unscaled, y_scaler_train, y_scaler_test = generate_data(df, sequence_length, n_ahead)\n",
    "    \n",
    "    for model_id in models:\n",
    "        for run in range(10):\n",
    "            if model_id == 'TKAN':\n",
    "                model = Sequential([\n",
    "                    Input(shape=X_train.shape[1:]),\n",
    "                    TKAN(**tkan_config(return_sequences=True)),\n",
    "                    TKAN(**tkan_config(return_sequences=False)),\n",
    "                    Dense(units=n_ahead, activation='linear')\n",
    "                ], name=model_id)\n",
    "\n",
    "            elif model_id == 'SigTKAN':\n",
    "                model = Sequential([\n",
    "                    Input(shape=X_train.shape[1:]),\n",
    "                    SigTKAN(sig_level=2, **tkan_config(return_sequences=True)),\n",
    "                    SigTKAN(sig_level=2, **tkan_config(return_sequences=False)),\n",
    "                    Dense(units=n_ahead, activation='linear')\n",
    "                ], name=model_id)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model_id: {model_id}\")\n",
    "\n",
    "            optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "            model.compile(optimizer=optimizer, loss='mean_squared_error', jit_compile=True)\n",
    "            if run == 0:\n",
    "                model.summary()\n",
    "\n",
    "            start_time = time.time()\n",
    "            history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=N_MAX_EPOCHS, validation_split=0.2, callbacks=callbacks(), shuffle=True, verbose=False)\n",
    "            end_time = time.time()\n",
    "            time_results[model_id][n_ahead].append(end_time - start_time)\n",
    "\n",
    "            preds = model.predict(X_test, verbose=False)\n",
    "            r2 = r2_score(y_true=y_test, y_pred=preds)\n",
    "            rmse = np.sqrt(np.mean((y_test - preds) ** 2))\n",
    "            \n",
    "            errors = preds - y_test\n",
    "            all_errors[model_id][n_ahead].append(errors)\n",
    "\n",
    "            print(end_time - start_time, r2)\n",
    "\n",
    "            results[model_id][n_ahead].append(r2)\n",
    "            results_rmse[model_id][n_ahead].append(rmse)\n",
    "\n",
    "            del model\n",
    "            del optimizer\n",
    "\n",
    "\n",
    "print('R2 scores - Means:')\n",
    "display(pd.DataFrame({model_id: {n_ahead: np.mean(results[model_id][n_ahead]) for n_ahead in n_aheads} for model_id in results}))\n",
    "\n",
    "print('RMSE scores - Means:')\n",
    "display(pd.DataFrame({model_id: {n_ahead: np.mean(results_rmse[model_id][n_ahead]) for n_ahead in n_aheads} for model_id in results_rmse}))\n",
    "\n",
    "print('R2 scores - Std:')\n",
    "display(pd.DataFrame({model_id: {n_ahead: np.std(results[model_id][n_ahead]) for n_ahead in n_aheads} for model_id in results}))\n",
    "\n",
    "print('RMSE scores - Std:')\n",
    "display(pd.DataFrame({model_id: {n_ahead: np.std(results_rmse[model_id][n_ahead]) for n_ahead in n_aheads} for model_id in results_rmse}))\n",
    "\n",
    "print('Training Times - Means:')\n",
    "display(pd.DataFrame({model_id: {n_ahead: np.mean(time_results[model_id][n_ahead]) for n_ahead in n_aheads} for model_id in time_results}))\n",
    "\n",
    "print('Training Times - Std:')\n",
    "display(pd.DataFrame({model_id: {n_ahead: np.std(time_results[model_id][n_ahead]) for n_ahead in n_aheads} for model_id in time_results}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16e729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Préparer all_errors pour le plot\n",
    "all_errors_plot = {}\n",
    "all_errors_plot['TKAN'] = np.mean(all_errors['TKAN'][1], axis=0)\n",
    "all_errors_plot['SigTKAN'] = np.mean(all_errors['SigTKAN'][1], axis=0)    \n",
    "\n",
    "model_types = ['TKAN', 'SigTKAN']\n",
    "colors = ['#1f77b4', '#2ca02c'] \n",
    "\n",
    "for model_type, color in zip(model_types, colors):\n",
    "    y_pred = all_errors_plot[model_type] + y_test\n",
    "    r2 = r2_score(y_true=y_test.flatten(), y_pred=y_pred.flatten())\n",
    "    plt.plot(np.mean(all_errors_plot[model_type]**2, axis=0), label=f'{model_type}: R²={round(r2,4)}', color=color)\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Model and errors based on number of steps forward')\n",
    "plt.xlabel('number of steps forward')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506db239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
